var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"Modules = [SequentialSamplingModels]\nOrder   = [:type, :function]","category":"page"},{"location":"api/#SequentialSamplingModels.DDM","page":"API","title":"SequentialSamplingModels.DDM","text":"DDM\n\nModel object for the Drift Diffusion Model. \n\nFields\n\nν: drift rate\nη: across-trial drift rate standard deviation\nα: evidence threshold \nz: mean starting point\nsz: range of starting point variability\nτ: non-decision time \nst: range of non-decision time\nσ: diffusion noise \nΔt: time step \n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.DDM-Tuple{}","page":"API","title":"SequentialSamplingModels.DDM","text":"DDM(; ν = 0.50,     η = 0.10,     α = 0.08,     z = 0.04,     sz = 0.02,     τ = 0.30,     st = .02,     σ = 0.10,     Δt = 0.001)\n\nConstructor for Drift Diffusion Model model. \n\nKeywords\n\nν=.50: drift rates \nη=0.10: across-trial drift rate standard deviation\nα=0.08: evidence threshold \nz=0.04: mean starting point\nsz=0.02: range of starting point variability\nτ=0.3: non-decision time \nst=0.02: range of non-decision time\nσ=0.10: diffusion noise \nΔt=.001: time step \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.DiffusionRace","page":"API","title":"SequentialSamplingModels.DiffusionRace","text":"DiffusionRace(;ν, k, A, θ)\n\nAn object for the racing diffusion model. \n\nFields\n\nν: a vector of drift rates\nk: k = b - A where b is the decision threshold, and A is the maximum starting point\nA: the maximum starting point diffusion process, sampled from Uniform distribution\nθ: a encoding-motor time offset\n\nExample\n\nusing SequentialSamplingModels\ndist = DiffusionRace(;ν=[1,2], k=.3, A=.7, θ=.2)\ndata = rand(dist, 10)\nlike = pdf.(dist, data)\nloglike = logpdf.(dist, data)\n\nReferences\n\nTillman, G., Van Zandt, T., & Logan, G. D. (2020). Sequential sampling models without random between-trial variability:  The racing diffusion model of speeded decision making. Psychonomic Bulletin & Review, 27, 911-936.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.LBA","page":"API","title":"SequentialSamplingModels.LBA","text":"LBA(;τ, A, k, ν, σ=1.0)\n\nA model object for the linear ballistic accumulator.\n\nFields\n\nν: a vector of drift rates\nA: max start point\nk: A + k = b, where b is the decision threshold\nσ=1: drift rate standard deviation\nτ: a encoding-response offset\n\nExample\n\nusing SequentialSamplingModels\ndist = LBA(ν=[3.0,2.0], A = .8, k = .2, τ = .3) \nchoice,rt = rand(dist, 10)\nlike = pdf.(dist, choice, rt)\nloglike = logpdf.(dist, choice, rt)\n\nReferences\n\nBrown, S. D., & Heathcote, A. (2008). The simplest complete model of choice response time: Linear ballistic accumulation. Cognitive psychology, 57(3), 153-178.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.LCA","page":"API","title":"SequentialSamplingModels.LCA","text":"LCA\n\nModel object for the Leaky Competing Accumulator. \n\nFields\n\nν: drift rates \nα: evidence threshold \nβ: lateral inhabition \nλ: leak rate\nτ: non-decision time \nσ: diffusion noise \nΔt: time step \n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.LCA-Tuple{}","page":"API","title":"SequentialSamplingModels.LCA","text":"LCA(;ν = [2.5,2.0], \n    α = 1.5, \n    β = .20, \n    λ = .10, \n    τ = .30, \n    σ = 1.0, \n    Δt = .001)\n\nConstructor for Leaky Competing Accumulator model. \n\nKeywords\n\nν = [2.5,2.0]: drift rates \nα = 1.5: evidence threshold \nβ = .20: lateral inhabition \nλ = .10: leak rate\nτ = .30: non-decision time \nσ = 1.0: diffusion noise \nΔt = .001: time step \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.LNR","page":"API","title":"SequentialSamplingModels.LNR","text":"LNR(;μ, σ, ϕ)\n\nA lognormal race model object \n\nFields\n\nμ: a vector of means in log-space\nσ: a standard deviation parameter in log-space\nϕ: a encoding-response offset\n\nExample\n\nusing SequentialSamplingModels\ndist = LNR(μ=[-2,-3], σ=1.0, ϕ=.3)\ndata = rand(dist, 10)\nlike = pdf.(dist, data)\nloglike = logpdf.(dist, data)\n\nReferences\n\nRouder, J. N., Province, J. M., Morey, R. D., Gomez, P., & Heathcote, A. (2015).  The lognormal race: A cognitive-process model of choice and latency with desirable  psychometric properties. Psychometrika, 80(2), 491-513.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.Wald","page":"API","title":"SequentialSamplingModels.Wald","text":"Wald Constructor\n\nυ: drift rate\nα: decision threshold\nθ: a encoding-response offset\n\nUsage\n\nusing SequentialSamplingModels\ndist = Wald(υ=3.0, α=.5, θ=.130)\nrt = rand(dist, 10)\nlike = pdf.(dist, rt)\nloglike = logpdf.(dist, rt)\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.WaldA","page":"API","title":"SequentialSamplingModels.WaldA","text":"WaldA(;ν, k, A, θ)\n\nConstructor for Wald distribution \n\nFields\n\nν: drift rate\nk: k = b - A where b is the decision threshold, and A is the maximum starting point\nA: the maximum starting point diffusion process, sampled from Uniform distribution\nθ: a encoding-motor time offset\n\nUsage\n\nusing SequentialSamplingModels\ndist = WaldA(ν=.5, σ=1.0, ϕ=.3)\ndata = rand(dist, 10)\nlike = pdf.(dist, data)\nloglike = logpdf.(dist, data)\n\nReferences\n\nTillman, G., Van Zandt, T., & Logan, G. D. (2020). Sequential sampling models without random between-trial variability:  The racing diffusion model of speeded decision making. Psychonomic Bulletin & Review, 27, 911-936.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.WaldMixture","page":"API","title":"SequentialSamplingModels.WaldMixture","text":"WaldMixture Constructor\n\nυ: drift rate\nσ: standard deviation of drift rate\nα: decision threshold\nθ: a encoding-response offset\n\nUsage\n\nusing SequentialSamplingModels\ndist = WaldMixture(υ=3.0, σ=.2, α=.5, θ=.130)\nrt = rand(dist, 10)\nlike = pdf.(dist, rt)\nloglike = logpdf.(dist, rt)\n\nReferences\n\nSteingroever, H., Wabersich, D., & Wagenmakers, E. J. (2020).  Modeling across-trial variability in the Wald drift rate parameter.  Behavior Research Methods, 1-17.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.aDDM-Tuple{}","page":"API","title":"SequentialSamplingModels.aDDM","text":"aDDM(;ν1=5.0, ν2=4.0, α=1.0, z=α*.5, θ=.3, σ=.02, Δ=.0004)\n\nConstructor for attentional diffusion model object. \n\nKeywords\n\nν1=5.0: relative decision value for alternative 1\nν2=4.0: relative decision value for alternative 2\nα=1.0: evidence threshold \nz=0.0: initial evidence \nθ=.3: bias towards attended alternative (lower indicates more bias)\nσ=.02: standard deviation of noise in evidence accumulation\nΔ=.0004: constant of evidence accumulation speed (evidence per ms)\n\nReferences\n\nKrajbich, I., Armel, C., & Rangel, A. (2010). Visual fixations and the computation and comparison of  value in simple choice. Nature neuroscience, 13(10), 1292-1298.\n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.maaDDM-Tuple{}","page":"API","title":"SequentialSamplingModels.maaDDM","text":"maaDDM(; ν₁₁ = 4.0, \n        ν₁₂ = 5.0, \n        ν₂₁ = 5.0, \n        ν₂₂ = 4.0, \n        α = 1.0, \n        z = 0.0, \n        θ = .3, \n        ϕ = .50, \n        ω = .70, \n        σ = .02, \n        Δ = .0004)\n\nConstructor for multialternative attentional diffusion model object. \n\nIn this version of the model, the non-attended attribute of the non-attended alternative is doubly discounted. For example, the mean drift rate for the attribute 1 of alternative 1 is given by:\n\n    Δ * (ω * (ν₁₁ - θ * ν₂₁) + (1 - ω) * ϕ * (ν₁₂ - θ * ν₂₂))\n\nKeywords\n\nν₁₁=5.0: relative decision value for alternative 1, attribute 1\nν₁₂=4.0: relative decision value for alternative 1, attribute 2\nν₂₁=5.0: relative decision value for alternative 2, attribute 1\nν₂₂=4.0:  relative decision value for alternative 2, attribute 2\nα=1.0: evidence threshold \nz=0.0: initial evidence \nθ=.3: bias away from unattended alternative (lower indicates more bias)\nϕ=.50: bias away from unattended attribute \nω=.70: attribute weight\nσ=.02: standard deviation of noise in evidence accumulation\nΔ=.0004: constant of evidence accumulation speed (evidence per ms)\n\nReferences\n\nYang, X., & Krajbich, I. (2023). A dynamic computational model of gaze and choice in multi-attribute decisions.  Psychological Review, 130(1), 52.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{AbstractaDDM, Any, Vararg{Any}}","page":"API","title":"Base.rand","text":"rand(dist::aDDM, fixation, args...; kwargs...)\n\nGenerate a single simulated trial from the attention diffusion model.\n\nArguments\n\ndist: an attentional diffusion model object\nfixation: a function of the visual fixation process which returns 1 for alternative    and 2 for alternative 2\nargs...: optional positional arguments for the fixation function\n\nKeywords\n\nkwargs...: optional keyword arguments for the fixation function\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{AbstractaDDM, Int64, Any, Vararg{Any}}","page":"API","title":"Base.rand","text":"rand(dist::aDDM, n_sim::Int, fixation, args...; kwargs...)\n\nGenerate n_sim simulated trials from the attention diffusion model.\n\nArguments\n\ndist: an attentional diffusion model object\nn_sim::Int: the number of simulated trials\nfixation: a function of the visual fixation process which returns 1 for alternative    and 2 for alternative 2\nargs...: optional positional arguments for the fixation function\n\nKeywords\n\nkwargs...: optional keyword arguments for the fixation function\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{DDM, Int64}","page":"API","title":"Base.rand","text":"rand(dist::DDM, n_sim::Int)\n\nGenerate n_sim random choice-rt pairs for the Drift Diffusion Model.\n\nArguments\n\ndist: model object for the Drift Diffusion Model.\nn_sim::Int: the number of simulated choice-rt pairs  \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{DDM}","page":"API","title":"Base.rand","text":"rand(dist::DDM)\n\nGenerate a random choice-rt pair for the Drift Diffusion Model.\n\nArguments\n\ndist: model object for the Drift Diffusion Model. \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{LCA, Int64}","page":"API","title":"Base.rand","text":"rand(dist::LCA, n_sim::Int)\n\nGenerate n_sim random choice-rt pairs for the Leaky Competing Accumulator.\n\nArguments\n\ndist: model object for the Leaky Competing Accumulator.\nn_sim::Int: the number of simulated choice-rt pairs  \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{LCA}","page":"API","title":"Base.rand","text":"rand(dist::LCA)\n\nGenerate a random choice-rt pair for the Leaky Competing Accumulator.\n\nArguments\n\ndist: model object for the Leaky Competing Accumulator. \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.update-Tuple{aDDM, Any}","page":"API","title":"SequentialSamplingModels.update","text":"update(dist::aDDM, location)\n\nReturns the change evidence for a single iteration. \n\nArguments\n\ndist::aDDM: a model object for the attentional drift diffusion model\nlocation: an index for fixation location \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.update-Tuple{maaDDM, Any}","page":"API","title":"SequentialSamplingModels.update","text":"update(dist::maaDDM, location)\n\nReturns the change evidence for a single iteration. \n\nArguments\n\ndist::maaDDM: a model object for the multiattribute attentional drift diffusion model\nlocation: an index for fixation location \n\n\n\n\n\n","category":"method"},{"location":"wald/#Wald-Model","page":"Wald Model","title":"Wald Model","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"The Wald model is used to model single choice decisions. It is formally equivalent to a drift diffusion model with one decision threshold and no starting point or across trial drift rate variability.","category":"page"},{"location":"wald/#Example","page":"Wald Model","title":"Example","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"In this example, we will demonstrate how to use the LNR in a generic two alternative forced choice task. ","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nν = 3.0\nα = 0.50\nθ = 0.130\n\ndist = Wald(ν, α, θ)\n\nrts = rand(dist, 10_000)\nt_range = range(θ, 1, length=100)\npdf1 = pdf.(dist, t_range)\n# histogram of retrieval times\nhist = histogram(rts, leg=false, grid=false, norm=true,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,1))\nplot!(t_range, pdf1, subplot=1, color=:darkorange, linewidth=2)\nhist","category":"page"},{"location":"wald/#Load-Packages","page":"Wald Model","title":"Load Packages","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"The first step is to load the required packages.","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"wald/#Create-Model-Object","page":"Wald Model","title":"Create Model Object","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values. ","category":"page"},{"location":"wald/#Mean-Log-Time","page":"Wald Model","title":"Mean Log Time","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"The parameter mu represents the mean processing time of each accumulator in log space.","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"ν = 3.0","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"dist = Wald(ν, α, θ)","category":"page"},{"location":"wald/#Threshold","page":"Wald Model","title":"Threshold","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"The parameter sigma repesents the mean processing time in log space.","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"α = 0.50","category":"page"},{"location":"wald/#Non-Decision-Time","page":"Wald Model","title":"Non-Decision Time","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"θ = 0.130","category":"page"},{"location":"wald/#Wald-Constructor","page":"Wald Model","title":"Wald Constructor","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"Now that values have been asigned to the parameters, we will pass them to LNR to generate the model object.","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"dist = Wald(ν, α, θ)","category":"page"},{"location":"wald/#Simulate-Model","page":"Wald Model","title":"Simulate Model","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"rts = rand(dist, 1000)","category":"page"},{"location":"wald/#Compute-PDF","page":"Wald Model","title":"Compute  PDF","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"pdf.(dist, rts)","category":"page"},{"location":"wald/#Compute-Log-PDF","page":"Wald Model","title":"Compute Log PDF","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"logpdf.(dist, rts)","category":"page"},{"location":"wald/#Plot-Simulation","page":"Wald Model","title":"Plot Simulation","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"rts = rand(dist, 10_000)\nt_range = range(θ, 1, length=100)\npdf1 = pdf.(dist, t_range)\n# histogram of retrieval times\nhist = histogram(rts, leg=false, grid=false, norm=true, color=:grey,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,1))\nplot!(t_range, pdf1, subplot=1, color=:darkorange, linewidth=2)\nhist","category":"page"},{"location":"wald/#References","page":"Wald Model","title":"References","text":"","category":"section"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"Heathcote, A., & Love, J. (2012). Linear deterministic accumulator models of simple choice. Frontiers in psychology, 3, 292.","category":"page"},{"location":"wald/","page":"Wald Model","title":"Wald Model","text":"Rouder, J. N., Province, J. M., Morey, R. D., Gomez, P., & Heathcote, A. (2015). The lognormal race: A cognitive-process model of choice and latency with desirable psychometric properties. Psychometrika, 80, 491-513.","category":"page"},{"location":"lba/#Linear-Ballistic-Accumulator","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"The Linear Ballistic Accumulator (LBA; Brown & Heathcote, 2008) is a sequential sampling model in which evidence for options races independently. The LBA makes an additional simplification that evidence accumulates in a linear and ballistic fashion, meaning there is no intra-trial noise. Instead, evidence accumulates deterministically and linearly until it hits the threshold.","category":"page"},{"location":"lba/#Example","page":"Linear Ballistic Accumulator","title":"Example","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"In this example, we will demonstrate how to use the LBA in a generic two alternative forced choice task. ","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nν=[2.75,1.75]\nA = .8\nk = .5\nτ = .3\n\ndist = LBA(;ν, A, k, τ) \nchoices,rts = rand(dist, 100)\n\n# rts for option 1\nrts1 = rts[choices .== 1]\n# rts for option 2 \nrts2 = rts[choices .== 2]\n# probability of choosing 1\np1 = length(rts1) / length(rts)\nt_range = range(.31, 2, length=100)\n# pdf for choice 1\npdf1 = pdf.(dist, (1,), t_range)\n# pdf for choice 2\npdf2 = pdf.(dist, (2,), t_range)\n# histogram of retrieval times\nhist = histogram(layout=(2,1), leg=false, grid=false,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,1.5))\nhistogram!(rts1, subplot=1, color=:grey, bins = 200, norm=true, title=\"Choice 1\")\nplot!(t_range, pdf1, subplot=1, color=:darkorange, linewidth=2)\nhistogram!(rts2, subplot=2, color=:grey, bins = 150, norm=true, title=\"Choice 2\")\nplot!(t_range, pdf2, subplot=2, color=:darkorange, linewidth=2)\n# weight histogram according to choice probability\nhist[1][1][:y] *= p1\nhist[2][1][:y] *= (1 - p1)\nhist","category":"page"},{"location":"lba/#Load-Packages","page":"Linear Ballistic Accumulator","title":"Load Packages","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"The first step is to load the required packages.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"lba/#Create-Model-Object","page":"Linear Ballistic Accumulator","title":"Create Model Object","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values. ","category":"page"},{"location":"lba/#Drift-Rates","page":"Linear Ballistic Accumulator","title":"Drift Rates","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"The drift rates control the speed with which information accumulates. Typically, there is one drift rate per option. ","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"ν=[2.75,1.75]","category":"page"},{"location":"lba/#Maximum-Starting-Point","page":"Linear Ballistic Accumulator","title":"Maximum Starting Point","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"The starting point of each accumulator is sampled uniformly between 0A.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"A = 0.80","category":"page"},{"location":"lba/#Threshold-Maximum-Starting-Point","page":"Linear Ballistic Accumulator","title":"Threshold - Maximum Starting Point","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"Evidence accumulates until accumulator reaches a threshold alpha = k +A. The threshold is parameterized this way to faciliate parameter estimation and to ensure that A le alpha.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"k = 0.50","category":"page"},{"location":"lba/#Non-Decision-Time","page":"Linear Ballistic Accumulator","title":"Non-Decision Time","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"τ = 0.30","category":"page"},{"location":"lba/#LBA-Constructor","page":"Linear Ballistic Accumulator","title":"LBA Constructor","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"Now that values have been asigned to the parameters, we will pass them to LBA to generate the model object.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"dist = LBA(; ν, A, k, τ) ","category":"page"},{"location":"lba/#Simulate-Model","page":"Linear Ballistic Accumulator","title":"Simulate Model","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":" choices,rts = rand(dist, 10_000)","category":"page"},{"location":"lba/#Compute-PDF","page":"Linear Ballistic Accumulator","title":"Compute PDF","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"pdf.(dist, choices, rts)","category":"page"},{"location":"lba/#Compute-Log-PDF","page":"Linear Ballistic Accumulator","title":"Compute Log PDF","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"logpdf.(dist, choices, rts)","category":"page"},{"location":"lba/#Plot-Simulation","page":"Linear Ballistic Accumulator","title":"Plot Simulation","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"# rts for option 1\nrts1 = rts[choices .== 1]\n# rts for option 2 \nrts2 = rts[choices .== 2]\n# probability of choosing 1\np1 = length(rts1) / length(rts)\nt_range = range(.31, 2, length=100)\n# pdf for choice 1\npdf1 = pdf.(dist, (1,), t_range)\n# pdf for choice 2\npdf2 = pdf.(dist, (2,), t_range)\n# histogram of retrieval times\nhist = histogram(layout=(2,1), leg=false, grid=false,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,1.5))\nhistogram!(rts1, subplot=1, color=:grey, bins = 200, norm=true, title=\"Choice 1\")\nplot!(t_range, pdf1, subplot=1, color=:darkorange, linewidth=2)\nhistogram!(rts2, subplot=2, color=:grey, bins = 150, norm=true, title=\"Choice 2\")\nplot!(t_range, pdf2, subplot=2, color=:darkorange, linewidth=2)\n# weight histogram according to choice probability\nhist[1][1][:y] *= p1\nhist[2][1][:y] *= (1 - p1)\nhist","category":"page"},{"location":"lba/#References","page":"Linear Ballistic Accumulator","title":"References","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator","title":"Linear Ballistic Accumulator","text":"Brown, S. D., & Heathcote, A. (2008). The simplest complete model of choice response time: Linear ballistic accumulation. Cognitive psychology, 57(3), 153-178.","category":"page"},{"location":"rdm/#Racing-Diffusion-Model","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"The Diffusion Race Model (DRM; Tillman, Van Zandt, & Logan, 2020) is a sequential sampling model in which evidence for options races independently. The LBA makes an additional simplification that evidence accumulates in a linear and ballistic fashion, meaning there is no intra-trial noise. Instead, evidence accumulates deterministically and linearly until it hits the threshold.","category":"page"},{"location":"rdm/#Example","page":"Racing Diffusion Model","title":"Example","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"In this example, we will demonstrate how to use the LBA in a generic two alternative forced choice task. ","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nν = [1.0,0.50]\nk = 0.50\nA = 1.0\nθ = 0.20\n\ndist = DiffusionRace(;ν, k, A, θ)\nchoices,rts = rand(dist, 1000)\n\n# rts for option 1\nrts1 = rts[choices .== 1]\n# rts for option 2 \nrts2 = rts[choices .== 2]\n# probability of choosing 1\np1 = length(rts1) / length(rts)\nt_range = range(.31, 2, length=100)\n# pdf for choice 1\npdf1 = pdf.(dist, (1,), t_range)\n# pdf for choice 2\npdf2 = pdf.(dist, (2,), t_range)\n# histogram of retrieval times\nhist = histogram(layout=(2,1), leg=false, grid=false,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,1.5))\nhistogram!(rts1, subplot=1, color=:grey, bins = 200, norm=true, title=\"Choice 1\")\nplot!(t_range, pdf1, subplot=1, color=:darkorange, linewidth=2)\nhistogram!(rts2, subplot=2, color=:grey, bins = 150, norm=true, title=\"Choice 2\")\nplot!(t_range, pdf2, subplot=2, color=:darkorange, linewidth=2)\n# weight histogram according to choice probability\nhist[1][1][:y] *= p1\nhist[2][1][:y] *= (1 - p1)\nhist","category":"page"},{"location":"rdm/#Load-Packages","page":"Racing Diffusion Model","title":"Load Packages","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"The first step is to load the required packages.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"rdm/#Create-Model-Object","page":"Racing Diffusion Model","title":"Create Model Object","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values. ","category":"page"},{"location":"rdm/#Drift-Rates","page":"Racing Diffusion Model","title":"Drift Rates","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"The drift rates control the speed with which information accumulates. Typically, there is one drift rate per option. ","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"ν = [1.0,0.50]","category":"page"},{"location":"rdm/#Maximum-Starting-Point","page":"Racing Diffusion Model","title":"Maximum Starting Point","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"The starting point of each accumulator is sampled uniformly between 0A.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"A = 0.80","category":"page"},{"location":"rdm/#Threshold-Maximum-Starting-Point","page":"Racing Diffusion Model","title":"Threshold - Maximum Starting Point","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"Evidence accumulates until accumulator reaches a threshold alpha = k +A. The threshold is parameterized this way to faciliate parameter estimation and to ensure that A le alpha.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"k = 0.50","category":"page"},{"location":"rdm/#Non-Decision-Time","page":"Racing Diffusion Model","title":"Non-Decision Time","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"θ  = 0.30","category":"page"},{"location":"rdm/#LBA-Constructor","page":"Racing Diffusion Model","title":"LBA Constructor","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"Now that values have been asigned to the parameters, we will pass them to LBA to generate the model object.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"dist = DiffusionRace(;ν, k, A, θ)","category":"page"},{"location":"rdm/#Simulate-Model","page":"Racing Diffusion Model","title":"Simulate Model","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":" choices,rts = rand(dist, 10_000)","category":"page"},{"location":"rdm/#Compute-PDF","page":"Racing Diffusion Model","title":"Compute PDF","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"pdf.(dist, choices, rts)","category":"page"},{"location":"rdm/#Compute-Log-PDF","page":"Racing Diffusion Model","title":"Compute Log PDF","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"logpdf.(dist, choices, rts)","category":"page"},{"location":"rdm/#Plot-Simulation","page":"Racing Diffusion Model","title":"Plot Simulation","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"# rts for option 1\nrts1 = rts[choices .== 1]\n# rts for option 2 \nrts2 = rts[choices .== 2]\n# probability of choosing 1\np1 = length(rts1) / length(rts)\nt_range = range(.31, 2, length=100)\n# pdf for choice 1\npdf1 = pdf.(dist, (1,), t_range)\n# pdf for choice 2\npdf2 = pdf.(dist, (2,), t_range)\n# histogram of retrieval times\nhist = histogram(layout=(2,1), leg=false, grid=false,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,1.5))\nhistogram!(rts1, subplot=1, color=:grey, bins = 200, norm=true, title=\"Choice 1\")\nplot!(t_range, pdf1, subplot=1, color=:darkorange, linewidth=2)\nhistogram!(rts2, subplot=2, color=:grey, bins = 150, norm=true, title=\"Choice 2\")\nplot!(t_range, pdf2, subplot=2, color=:darkorange, linewidth=2)\n# weight histogram according to choice probability\nhist[1][1][:y] *= p1\nhist[2][1][:y] *= (1 - p1)\nhist","category":"page"},{"location":"rdm/#References","page":"Racing Diffusion Model","title":"References","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model","title":"Racing Diffusion Model","text":"Tillman, G., Van Zandt, T., & Logan, G. D. (2020). Sequential sampling models without random between-trial variability: The racing diffusion model of speeded decision making. Psychonomic Bulletin & Review, 27, 911-936.","category":"page"},{"location":"aDDM/#Attentional-Drift-Diffusion-Model","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion Model","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The attentional drift diffusion model (ADDM; Krajbich, Armel, & Rangel, 2010) describes how attentional processes drive drive decision making. In the ADDM, preference for the currently attended option accrues faster than preference for non-attended options. As with other sequential sampling models, the first option to hit a decision threshold determines the resulting choice and reaction time.","category":"page"},{"location":"aDDM/#Example","page":"Attentional Drift Diffusion","title":"Example","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"using SequentialSamplingModels\nusing StatsBase\nusing Plots\nusing Random\n\nRandom.seed!(5487)\n\nmutable struct Transition\n    state::Int \n    n::Int\n    mat::Array{Float64,2} \n end\n\n function Transition(mat)\n    n = size(mat,1)\n    state = rand(1:n)\n    return Transition(state, n, mat)\n end\n \n function attend(transition)\n     (;mat,n,state) = transition\n     w = mat[state,:]\n     next_state = sample(1:n, Weights(w))\n     transition.state = next_state\n     return next_state\n end\n\nν1 = 6.0\nν2 = 5.0\nα = 1.0\nz = 0.0\nθ = 0.30\nσ = 0.02\nΔ = 0.0004  \n\n model = aDDM(; ν1, ν2, α, z, θ, σ, Δ)\n \n tmat = Transition([.98 .015 .005;\n                    .015 .98 .005;\n                    .45 .45 .1])\n\n choices,rts = rand(model, 100, attend, tmat)\n\n# rts for option 1\nrts1 = rts[choices .== 1]\n# rts for option 2 \nrts2 = rts[choices .== 2]\n# probability of choosing 1\np1 = length(rts1) / length(rts)\n# histogram of retrieval times\nhist = histogram(layout=(2,1), leg=false, grid=false,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,5), ylims=(0,.5))\nhistogram!(rts1, subplot=1, color=:grey, bins = 100, norm=true, title=\"Choice 1\")\nhistogram!(rts2, subplot=2, color=:grey, bins = 100, norm=true, title=\"Choice 2\")\n# weight histogram according to choice probability\nhist[1][1][:y] *= p1\nhist[2][1][:y] *= (1 - p1)\nhist","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"In this example, we will develope a ADDM for binary choice and generate its predictions. Unlike many other sequential sampling models, it is necessary to specify the attentional process, or supply fixation patterns from eye tracking data. ","category":"page"},{"location":"aDDM/#Load-Packages","page":"Attentional Drift Diffusion","title":"Load Packages","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The first step is to load the required packages.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"using SequentialSamplingModels\nusing StatsBase\nusing Plots\n\nRandom.seed!(5487)","category":"page"},{"location":"aDDM/#Define-Transition-Type","page":"Attentional Drift Diffusion","title":"Define Transition Type","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"To represent the transition of attention from one option to the other, we will definite a Transition type and constructor. The fields of the Transition type are:","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"state: an index for the current state\nn: the number of states\nmat: an ntimes n transition matrix","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The constructor accepts a transition matrix, extracts the number of states, and initializes the first state randomly with equal probability.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"mutable struct Transition\n    state::Int \n    n::Int\n    mat::Array{Float64,2} \n end\n\nfunction Transition(mat)\n    n = size(mat,1)\n    state = rand(1:n)\n    return Transition(state, n, mat)\n end","category":"page"},{"location":"aDDM/#Define-Transition-Matrix","page":"Attentional Drift Diffusion","title":"Define Transition Matrix","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The transition matrix is defined below in the constructor for Transition. As shown in the table below, the model's attention can be in one of three states: option 1, option 2, or non-option, which is any area except the two options. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":" option 1 option 2 non-option\noption 1 0.98 0.015 0.005\noption 2 0.015 0.98 0.005\nnon-option 0.45 0.45 0.1","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The transition matrix above embodies the following assumptions:","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"Once the model attends to an option, it dwells on the option for some time.\nThere is not a bias for one option over the other.\nThe chance of fixating on a non-option is small, and such fixations are brief when they do occur.\nTransitions are Markovian in that they only depend on the previous state.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"tmat = Transition([.98 .015 .005;\n                    .015 .98 .005;\n                    .45 .45 .1])","category":"page"},{"location":"aDDM/#Attend-Function","page":"Attentional Drift Diffusion","title":"Attend Function","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The function below generates the next attention location based on the previous location. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":" function attend(transition)\n     (;mat,n,state) = transition\n     w = mat[state,:]\n     next_state = sample(1:n, Weights(w))\n     transition.state = next_state\n     return next_state\n end","category":"page"},{"location":"aDDM/#Create-Model-Object","page":"Attentional Drift Diffusion","title":"Create Model Object","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The code snippets assign values to parameters of the ADDM and create a model object.","category":"page"},{"location":"aDDM/#Drift-Rate-Components","page":"Attentional Drift Diffusion","title":"Drift Rate Components","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The ADDM has two drift rates components corresponding to the utlity of each option. To form the drift rate, each component is weighted by non-attention bias and then a difference is computed.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"ν1 = 6.0\nν2 = 5.0","category":"page"},{"location":"aDDM/#Threshold","page":"Attentional Drift Diffusion","title":"Threshold","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The threshold hold represents the amount of evidence required to make a decision. This parameter is typically fixed at alpha = 1.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"α = 1.0","category":"page"},{"location":"aDDM/#Starting-Point","page":"Attentional Drift Diffusion","title":"Starting Point","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The starting point of the evidence accumulation process is denoted z and is typically fixed to 0.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"z = 0.0","category":"page"},{"location":"aDDM/#Non-Attend-Bias","page":"Attentional Drift Diffusion","title":"Non-Attend Bias","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The non-attend bias parameter theta determines how much the non-attended option contributes to the  evidence accumulation process. In the standard DDM, theta=1. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"θ = 0.30","category":"page"},{"location":"aDDM/#Diffusion-Noise","page":"Attentional Drift Diffusion","title":"Diffusion Noise","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"Diffusion noise, sigma represents intra-trial noise during the evidence accumulation process.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"σ = 0.02","category":"page"},{"location":"aDDM/#Drift-Rate-Scalar","page":"Attentional Drift Diffusion","title":"Drift Rate Scalar","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"The drift rate scalar controls how quickly evidence accumulates for each option. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"Δ = 0.0004 ","category":"page"},{"location":"aDDM/#Model-Object","page":"Attentional Drift Diffusion","title":"Model Object","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"Finally, we pass the parameters to the aDDM constructor to initialize the model.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":" model = aDDM(; ν1, ν2, α, z, θ, σ, Δ)","category":"page"},{"location":"aDDM/#Simulate-Model","page":"Attentional Drift Diffusion","title":"Simulate Model","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. The rand function accepts the model object, the number of simulated trials, the attend function, and the transition matrix object. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":" choices,rts = rand(model, 10_000, attend, tmat)","category":"page"},{"location":"aDDM/#Plot-Simulation","page":"Attentional Drift Diffusion","title":"Plot Simulation","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"Finally, we can generate histograms of the reaction times for each decision option. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"# rts for option 1\nrts1 = rts[choices .== 1]\n# rts for option 2 \nrts2 = rts[choices .== 2]\n# probability of choosing 1\np1 = length(rts1) / length(rts)\n# histogram of retrieval times\nhist = histogram(layout=(2,1), leg=false, grid=false,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,5), ylims=(0,.5))\nhistogram!(rts1, subplot=1, color=:grey, bins = 100, norm=true, title=\"Choice 1\")\nhistogram!(rts2, subplot=2, color=:grey, bins = 100, norm=true, title=\"Choice 2\")\n# weight histogram according to choice probability\nhist[1][1][:y] *= p1\nhist[2][1][:y] *= (1 - p1)\nhist","category":"page"},{"location":"aDDM/#References","page":"Attentional Drift Diffusion","title":"References","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion","title":"Attentional Drift Diffusion","text":"Krajbich, I., Armel, C., & Rangel, A. (2010). Visual fixations and the computation and comparison of value in simple choice. Nature neuroscience, 13(10), 1292-1298.","category":"page"},{"location":"lnr/#Lognormal-Race-Model","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"The Lognormal Race model (LNR) assumes evidence for each option races independently and that the first passage time for each option is lognormally distributed. One way in which the LNR has been used is to provide a likelihood function for the ACT-R cognitive architecture. An example of such an application can be found in ACTRModels.jl. We will present a simplified version below.","category":"page"},{"location":"lnr/#Example","page":"Lognormal Race Model","title":"Example","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"In this example, we will demonstrate how to use the LNR in a generic two alternative forced choice task. ","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nμ = [-1,-1.5]\nσ = 0.50\nϕ = 0.30\n\ndist = LNR(μ, σ, ϕ)\n\nchoices,rts = rand(dist, 1000)\n\n# rts for option 1\nrts1 = rts[choices .== 1]\n# rts for option 2 \nrts2 = rts[choices .== 2]\n# probability of choosing 1\np1 = length(rts1) / length(rts)\nt_range = range(.31, 1, length=100)\n# pdf for choice 1\npdf1 = pdf.(dist, (1,), t_range)\n# pdf for choice 2\npdf2 = pdf.(dist, (2,), t_range)\n# histogram of retrieval times\nhist = histogram(layout=(2,1), leg=false, grid=false,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,1.5))\nhistogram!(rts1, subplot=1, color=:grey, bins = 100, norm=true, title=\"Choice 1\")\nplot!(t_range, pdf1, subplot=1, color=:darkorange, linewidth=2)\nhistogram!(rts2, subplot=2, color=:grey, bins = 100, norm=true, title=\"Choice 2\")\nplot!(t_range, pdf2, subplot=2, color=:darkorange, linewidth=2)\n# weight histogram according to choice probability\nhist[1][1][:y] *= p1\nhist[2][1][:y] *= (1 - p1)\nhist","category":"page"},{"location":"lnr/#Load-Packages","page":"Lognormal Race Model","title":"Load Packages","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"The first step is to load the required packages.","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"lnr/#Create-Model-Object","page":"Lognormal Race Model","title":"Create Model Object","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values. ","category":"page"},{"location":"lnr/#Mean-Log-Time","page":"Lognormal Race Model","title":"Mean Log Time","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"The parameter mu represents the mean processing time of each accumulator in log space.","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"μ = [-1,-1.5]","category":"page"},{"location":"lnr/#Log-Standard-Deviation","page":"Lognormal Race Model","title":"Log Standard Deviation","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"The parameter sigma repesents the mean processing time in log space.","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"σ = 0.50","category":"page"},{"location":"lnr/#Non-Decision-Time","page":"Lognormal Race Model","title":"Non-Decision Time","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"ϕ = 0.30","category":"page"},{"location":"lnr/#LNR-Constructor","page":"Lognormal Race Model","title":"LNR Constructor","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"Now that values have been asigned to the parameters, we will pass them to LNR to generate the model object.","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"dist = LNR(μ, σ, ϕ)","category":"page"},{"location":"lnr/#Simulate-Model","page":"Lognormal Race Model","title":"Simulate Model","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":" choices,rts = rand(dist, 10_000)","category":"page"},{"location":"lnr/#Compute-PDF","page":"Lognormal Race Model","title":"Compute PDF","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"pdf.(dist, choices, rts)","category":"page"},{"location":"lnr/#Compute-Log-PDF","page":"Lognormal Race Model","title":"Compute Log PDF","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"logpdf.(dist, choices, rts)","category":"page"},{"location":"lnr/#Plot-Simulation","page":"Lognormal Race Model","title":"Plot Simulation","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"# rts for option 1\nrts1 = rts[choices .== 1]\n# rts for option 2 \nrts2 = rts[choices .== 2]\n# probability of choosing 1\np1 = length(rts1) / length(rts)\nt_range = range(.31, 1, length=100)\n# pdf for choice 1\npdf1 = pdf.(dist, (1,), t_range)\n# pdf for choice 2\npdf2 = pdf.(dist, (2,), t_range)\n# histogram of retrieval times\nhist = histogram(layout=(2,1), leg=false, grid=false,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,1.5))\nhistogram!(rts1, subplot=1, color=:grey, bins = 100, norm=true, title=\"Choice 1\")\nplot!(t_range, pdf1, subplot=1, color=:darkorange, linewidth=2)\nhistogram!(rts2, subplot=2, color=:grey, bins = 100, norm=true, title=\"Choice 2\")\nplot!(t_range, pdf2, subplot=2, color=:darkorange, linewidth=2)\n# weight histogram according to choice probability\nhist[1][1][:y] *= p1\nhist[2][1][:y] *= (1 - p1)\nhist","category":"page"},{"location":"lnr/#References","page":"Lognormal Race Model","title":"References","text":"","category":"section"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"Heathcote, A., & Love, J. (2012). Linear deterministic accumulator models of simple choice. Frontiers in psychology, 3, 292.","category":"page"},{"location":"lnr/","page":"Lognormal Race Model","title":"Lognormal Race Model","text":"Rouder, J. N., Province, J. M., Morey, R. D., Gomez, P., & Heathcote, A. (2015). The lognormal race: A cognitive-process model of choice and latency with desirable psychometric properties. Psychometrika, 80, 491-513.","category":"page"},{"location":"turing/#Parameter-Estimation-with-Turing","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"","category":"section"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"It is possible to use Turing.jl to perform Bayesian parameter estimation on models defined in SequentialSamplingModels.jl. Below, we show you how to estimate the parameters for the Linear Ballistic Accumulator (LBA).","category":"page"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"using Turing\nusing SequentialSamplingModels\nusing Random\nusing LinearAlgebra\nusing StatsPlots\n\n@model model(data) = begin\n    min_rt = minimum(data[2])\n    ν ~ MvNormal(zeros(2), I * 2)\n    A ~ truncated(Normal(.8, .4), 0.0, Inf)\n    k ~ truncated(Normal(.2, .2), 0.0, Inf)\n    τ  ~ Uniform(0.0, min_rt)\n    data ~ LBA(;ν, A, k, τ )\nend\n\n# generate some data\nRandom.seed!(254)\ndist = LBA(ν=[3.0,2.0], A = .8, k = .2, τ = .3) \ndata = rand(dist, 100)\n\n# estimate parameters\nchain = sample(model(data), NUTS(1000, .65), MCMCThreads(), 1000, 4)","category":"page"},{"location":"turing/#Example","page":"Parameter Estimation with Turing","title":"Example","text":"","category":"section"},{"location":"turing/#Load-Packages","page":"Parameter Estimation with Turing","title":"Load Packages","text":"","category":"section"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"The first step is to load the required packages. You will need to install each package in your local environment in order to run the code locally.","category":"page"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"using Turing\nusing SequentialSamplingModels\nusing Random\nusing LinearAlgebra","category":"page"},{"location":"turing/#Define-Turing-Model","page":"Parameter Estimation with Turing","title":"Define Turing Model","text":"","category":"section"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"The code snippet below defines a model in Turing. The model function accepts a tuple containing a vector of choices and a vector of reaction times. The sampling statements define the prior distributions for each parameter. The non-decision time parameter tau must be founded by the minimum reaction time, min_rt. The last sampling statement defines the likelihood of the data given the sampled parameter values. ","category":"page"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"@model model(data) = begin\n    min_rt = minimum(data[2])\n    ν ~ MvNormal(zeros(2), I * 2)\n    A ~ truncated(Normal(.8, .4), 0.0, Inf)\n    k ~ truncated(Normal(.2, .2), 0.0, Inf)\n    τ  ~ Uniform(0.0, min_rt)\n    data ~ LBA(;ν, A, k, τ )\nend","category":"page"},{"location":"turing/#Generate-Simulated-Data","page":"Parameter Estimation with Turing","title":"Generate Simulated Data","text":"","category":"section"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"In the code snippet below, we set a seed for the random number generator and generate 100 simulated trials from the LBA from which we will estimate parameters.","category":"page"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"# generate some data\nRandom.seed!(45461)\ndist = LBA(ν=[3.0,2.0], A = .8, k = .2, τ = .3) \ndata = rand(dist, 100)","category":"page"},{"location":"turing/#Estimate-the-Parameters","page":"Parameter Estimation with Turing","title":"Estimate the Parameters","text":"","category":"section"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"Finally, we perform parameter estimation with sample, which accepts the following inputs:","category":"page"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"model(data): the Turing model with data passed\nNUTS(1000, .65): a sampler object for the No U-Turn Sampler for 1000 warmup samples.\nMCMCThreads(): instructs turing to run each chain on a seperate thread\nn_iterations: the number of iterations performed after warmup\nn_chains: the number of chains","category":"page"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"# estimate parameters\nchain = sample(model(data), NUTS(1000, .85), MCMCThreads(), 1000, 4)","category":"page"},{"location":"turing/#Evaluation","page":"Parameter Estimation with Turing","title":"Evaluation","text":"","category":"section"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"It is important to verify that the chains converged. We see that the chains converged according to hatr leq 105, and the trace plots below show that the chains look like \"hairy catipillars\", whichin indictes the chains did not get stuck. As expected, the posterior distributions are close to the data generating parameter values.","category":"page"},{"location":"turing/","page":"Parameter Estimation with Turing","title":"Parameter Estimation with Turing","text":"plot(chain, grid=false)","category":"page"},{"location":"#SequentialSamplingModels.jl","page":"Home","title":"SequentialSamplingModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation is under construction.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This package is a collection of sequential sampling models and is based on the Distributions.jl API. Sequential sampling models, also known as an evidence accumulation models, are a broad class of dynamic models of human decision making in which evidence for each option accumulates until the evidence for one option reaches a decision threshold. Models within this class make different assumptions about the nature of the evidence accumulation process. An example of the evidence accumulation process is illustrated below for the leaking competing accumulator. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Plots\nusing Random\nusing Colors\nusing SequentialSamplingModels\nusing SequentialSamplingModels: increment!\nRandom.seed!(8437)\n\nfunction sim(model)\n    \n    n = length(model.ν)\n    x = fill(0.0, n)\n    μΔ = fill(0.0, n)\n    ϵ = fill(0.0, n)\n    t = 0.0\n    Δt = .005\n    evidence = Vector{Vector{Float64}}()\n    while all(x .< model.α)\n        t += Δt\n        increment!(model, x, μΔ, ϵ)\n        push!(evidence, copy(x))\n    end  \n    return t,evidence\nend\nparms = (α = 1.5, \n            β=0.20,\n             λ=0.10, \n             ν=[2.5,2.0], \n             Δt=.001, \n             τ=.30, \n             σ=1.0)\nmodel = LCA(; parms...)\nt,evidence = sim(model)\nn_steps = length(evidence)\ntime_steps = range(0, t, length=n_steps)\nlca_plot = plot(time_steps, hcat(evidence...)', xlabel=\"Time (seconds)\", ylabel=\"Evidence\", \n    label=[\"option1\" \"option2\"], ylims=(0, 2.0), grid=false, linewidth = 2,\n    color =[RGB(148/255, 90/255, 147/255) RGB(90/255, 112/255, 148/255)])\nhline!(lca_plot, [model.α], color=:black, linestyle=:dash, label=\"threshold\", linewidth = 2)","category":"page"},{"location":"","page":"Home","title":"Home","text":"lca_plot","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can install a stable version of SequentialSamplingModels by running the following in the Julia REPL:","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add SequentialSamplingModels","category":"page"},{"location":"","page":"Home","title":"Home","text":"The package can then be loaded with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using SequentialSamplingModels","category":"page"}]
}
