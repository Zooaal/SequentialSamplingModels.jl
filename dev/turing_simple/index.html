<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Simple Bayesian Model · SequentialSamplingModels</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="SequentialSamplingModels logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">SequentialSamplingModels</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Models</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../DDM/">Drift Diffusion Model (DDM)</a></li><li><a class="tocitem" href="../lba/">Linear Ballistic Accumulator (LBA)</a></li><li><a class="tocitem" href="../lnr/">Lognormal Race Model (LNR)</a></li><li><a class="tocitem" href="../rdm/">Racing Diffusion Model (RDM)</a></li><li><a class="tocitem" href="../lca/">Leaky Competing Accumulator (LCA)</a></li><li><a class="tocitem" href="../aDDM/">Attentional Drift Diffusion (aDDM)</a></li><li><a class="tocitem" href="../maaDDM/">Muti-attribute attentional drift diffusion Model</a></li><li><a class="tocitem" href="../wald/">Wald Model</a></li><li><a class="tocitem" href="../wald_mixture/">Wald Mixture Model</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">Parameter Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Simple Bayesian Model</a><ul class="internal"><li><a class="tocitem" href="#Load-Packages"><span>Load Packages</span></a></li><li><a class="tocitem" href="#Generate-Data"><span>Generate Data</span></a></li><li><a class="tocitem" href="#Specify-Turing-Model"><span>Specify Turing Model</span></a></li><li><a class="tocitem" href="#Estimate-the-Parameters"><span>Estimate the Parameters</span></a></li><li><a class="tocitem" href="#Posterior-Summary"><span>Posterior Summary</span></a></li><li><a class="tocitem" href="#Evaluation"><span>Evaluation</span></a></li><li><a class="tocitem" href="#Posterior-Predictive-Distribution"><span>Posterior Predictive Distribution</span></a></li></ul></li><li><a class="tocitem" href="../turing_advanced/">Advanced Model Specification</a></li><li><a class="tocitem" href="../turing_hierarchical/">Hierarchical Models</a></li></ul></li><li><a class="tocitem" href="../bayes_factor/">Model Comparison</a></li><li><a class="tocitem" href="../plotting/">Plotting</a></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../developer_guide/">Developer Guide</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Parameter Estimation</a></li><li class="is-active"><a href>Simple Bayesian Model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Simple Bayesian Model</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/itsdfish/SequentialSamplingModels.jl/blob/master/docs/src/turing_simple.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="A-Simple-Turing-Model"><a class="docs-heading-anchor" href="#A-Simple-Turing-Model">A Simple Turing Model</a><a id="A-Simple-Turing-Model-1"></a><a class="docs-heading-anchor-permalink" href="#A-Simple-Turing-Model" title="Permalink"></a></h1><p>It is possible to use <a href="https://turinglang.org/stable/">Turing.jl</a> to perform Bayesian parameter estimation on models defined in SequentialSamplingModels.jl. Below, we show you how to estimate the parameters for the <a href="https://itsdfish.github.io/SequentialSamplingModels.jl/dev/lba/">Linear Ballistic Accumulator (LBA)</a> and to use it to estimate effects.</p><p>Note that you can easily swap the LBA model from this example for other <a href="https://itsdfish.github.io/SequentialSamplingModels.jl/dev/api/">SSM models</a> simply by changing the names of the parameters.</p><h2 id="Load-Packages"><a class="docs-heading-anchor" href="#Load-Packages">Load Packages</a><a id="Load-Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Load-Packages" title="Permalink"></a></h2><p>The first step is to load the required packages. You will need to install each package in your local environment in order to run the code locally. We will also set a random number generator so that the results are reproducible.</p><pre><code class="language-julia hljs">using Turing
using SequentialSamplingModels
using Random
using LinearAlgebra
using StatsPlots
using Random

Random.seed!(45461)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Random.TaskLocalRNG()</code></pre><h2 id="Generate-Data"><a class="docs-heading-anchor" href="#Generate-Data">Generate Data</a><a id="Generate-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Generate-Data" title="Permalink"></a></h2><p>We will use the <a href="https://itsdfish.github.io/SequentialSamplingModels.jl/dev/lba/">LBA</a> distribution to simulate data (100 trials) with fixed parameters (those we want to recover only from the data using Bayesian modeling).</p><pre><code class="language-julia hljs"># Generate some data with known parameters
dist = LBA(ν=[3.0, 2.0], A = .8, k = .2, τ = .3)
data = rand(dist, 100)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(choice = [2, 1, 1, 1, 1, 1, 1, 1, 1, 2  …  2, 1, 1, 1, 1, 1, 2, 2, 1, 1], rt = [0.6290010134562214, 0.507511686077583, 0.4077035786951601, 0.5845853642627061, 0.5518606313501111, 0.357077395905047, 0.4430796909532061, 0.35525992231554643, 0.4858235685699115, 0.37197001383636874  …  0.8595469187781852, 0.5705118298266227, 0.5348699092588236, 0.4397605741138838, 0.48381613889237696, 0.4576847624125857, 0.4835375184039913, 0.5544902383424269, 0.583537266351565, 0.36048725612183097])</code></pre><p>The <code>rand()</code> function will sample random draws from the distribution, and store that into a named tuple of 2 vectors (one for <code>choice</code> and one for <code>rt</code>). The individual vectors can be accessed by their names using <code>data.choice</code> and <code>data.rt</code>.</p><h2 id="Specify-Turing-Model"><a class="docs-heading-anchor" href="#Specify-Turing-Model">Specify Turing Model</a><a id="Specify-Turing-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Specify-Turing-Model" title="Permalink"></a></h2><p>The code snippet below defines a model in Turing. The model function accepts a tuple containing a vector of choices and a vector of reaction times. The sampling statements define the prior distributions for each parameter. The non-decision time parameter <span>$\tau$</span> must be founded by the minimum reaction time, <code>min_rt</code>. The last sampling statement defines the likelihood of the data given the sampled parameter values.</p><pre><code class="language-julia hljs"># Specify LBA model
@model function model_lba(data; min_rt = minimum(data.rt))
    # Priors
    ν ~ MvNormal(zeros(2), I * 2)
    A ~ truncated(Normal(.8, .4), 0.0, Inf)
    k ~ truncated(Normal(.2, .2), 0.0, Inf)
    τ  ~ Uniform(0.0, min_rt)

    # Likelihood
    data ~ LBA(;ν, A, k, τ )
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">model_lba (generic function with 2 methods)</code></pre><h2 id="Estimate-the-Parameters"><a class="docs-heading-anchor" href="#Estimate-the-Parameters">Estimate the Parameters</a><a id="Estimate-the-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Estimate-the-Parameters" title="Permalink"></a></h2><p>Finally, we perform parameter estimation with <code>sample()</code>, which takes the model, and details about the sampling algorithm:</p><ol><li><code>model(data)</code>: the Turing model with data passed</li><li><code>NUTS(1000, .65)</code>: a sampler object for the No U-Turn Sampler for 1000 warmup samples.</li><li><code>MCMCThreads()</code>: instructs Turing to run each chain on a separate thread</li><li><code>n_iterations</code>: the number of iterations performed after warmup</li><li><code>n_chains</code>: the number of chains</li></ol><pre><code class="language- hljs"># Estimate parameters
chain = sample(model_lba(data), NUTS(1000, .85), MCMCThreads(), 1000, 4)</code></pre><h2 id="Posterior-Summary"><a class="docs-heading-anchor" href="#Posterior-Summary">Posterior Summary</a><a id="Posterior-Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Posterior-Summary" title="Permalink"></a></h2><p>We can compute a description of the posterior distributions.</p><pre><code class="language- hljs"># Summarize posteriors
summarystats(chain)</code></pre><p>As you can see, based on the mean values of the posterior distributions, the original parameters (<code>ν=[3.0, 2.0], A = .8, k = .2, τ = .3</code>) are successfully recovered from the data (the accuracy would increase with more data).</p><h2 id="Evaluation"><a class="docs-heading-anchor" href="#Evaluation">Evaluation</a><a id="Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluation" title="Permalink"></a></h2><p>It is important to verify that the chains converged. We see that the chains converged according to <span>$\hat{r} \leq 1.05$</span>, and the trace plots below show that the chains look like &quot;hairy caterpillars&quot;, which indicates the chains did not get stuck. As expected, the posterior distributions are close to the data generating parameter values.</p><pre><code class="language- hljs">plot(chain)</code></pre><h2 id="Posterior-Predictive-Distribution"><a class="docs-heading-anchor" href="#Posterior-Predictive-Distribution">Posterior Predictive Distribution</a><a id="Posterior-Predictive-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Posterior-Predictive-Distribution" title="Permalink"></a></h2><p>The next step is to generate predictions from the posterior distributions. For this, we need to pass a dataset with empty (<code>missing</code>) values (so that Turing knows what to predict).</p><p>We can then use the <code>predict()</code> method to generate predictions from this model. However, because the most of <code>SequentialSamplingModels</code> distributions return a tuple (choice and RT), the predicted output has the two types of variables mixed together. We can delineate the two by taking every 2nd values to get the predicted choice and RTs, respectively.</p><pre><code class="language- hljs">predictions = predict(model_lba(missing; min_rt = minimum(data.rt)), chain)

pred_choice = Array(predictions)[:, 1:2:end]
pred_rt = Array(predictions)[:, 2:2:end]</code></pre><p>In the following code block, we plot the predictive distributions for each choice.</p><pre><code class="language- hljs"># Get RTs for option 1 and 2
rts1 = pred_rt[pred_choice .== 1]
rts2 = pred_rt[pred_choice .== 2]

# Specify plot layout
histogram(layout=(2, 1), xlabel=&quot;RT&quot;, ylabel=&quot;Density&quot;, legend=false, xlims=(0, 1), ylim=(0, 150))
# Add data
histogram!(rts1, subplot=1, color=:grey, norm=false, title=&quot;Choice 1&quot;, bins=0:0.01:1)
histogram!(rts2, subplot=2, color=:grey, norm=false, title=&quot;Choice 2&quot;, bins=0:0.01:1)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../wald_mixture/">« Wald Mixture Model</a><a class="docs-footer-nextpage" href="../turing_advanced/">Advanced Model Specification »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Saturday 19 August 2023 10:48">Saturday 19 August 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
